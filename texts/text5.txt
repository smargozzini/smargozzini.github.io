Del paper de BPR, me gustó que se mostraran ejemplos de predicciones contra los métodos mas populares, esto causa mas impacto al ver que los resultados de estos métodos combinados con BPR son mejores por mucho. Me llamo la atención que en el ejemplo de netflix, una predicción BPR-MF de 8 dimensiones tenía los mismos resultados que una MF simple de 128 dimensiones. Esto quiere decir que con BPR se pueden lograr mejores resultados utilizando menos información, lo que afecta directamente en el tiempo necesario para entrenar el modelo y predecir ítems a los usuarios. Esto llevado a la realidad, puede tener gran impacto. 

Este paper lo encontré muy completo, mostrando información concisa con demostraciones precisas. Se puede inferir que los autores tienen mucho estudio en el tema y le dedicaron mucho tiempo al paper. Se preocupan de comparar sus métodos con los mas populares y te demuestran porque el suyo en mejor y en que puntos. Por ejemplo cuando hablan de WR-RF, dicen que es un método muy ocupado, que es una adaptación de SVD que minimiza el ‘square-loss’, pero que su método LearnBPR requiere menos tiempo en converger. También mencionan el método de MMMF y que es muy popular, pero cuando este método es aplicado para feedback implícito se necesita el dataset tiene que ser muy denso y descriptivo, algo que no es necesario al aplicar LearnBPR, esto lo maneja usando bootstraping del dataset.

Por último, me gustaría destacar la forma en que dividen el dataset y crean matrices de interés para todos los productos por cada usuario. Con esto saben preferencias y al mismo tiempo no pierden información asumiendo que ese ítem no les gusta y por eso no la han visto.